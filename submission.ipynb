{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from numpy import asarray\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import keras\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obb_model = YOLO('yolov8l-obb.pt')\n",
    "# obb_model.train(data='obb/data.yaml', epochs=45, imgsz=640, optimizer='AdamW')\n",
    "\n",
    "# seg_model = YOLO('yolov8n-seg.pt')\n",
    "# seg_model.train(data='seg/data.yaml', epochs=100, imgsz=640, optimizer='AdamW', single_cls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_color = (0, 0, 255)\n",
    "img_width, img_height = 244, 244\n",
    "ALL_L = 0\n",
    "ALL_M = 1\n",
    "BRICKS = 2\n",
    "LONGTRANS = 3\n",
    "RAVELING = 4\n",
    "THRESHOLD = 0.05\n",
    "all_l_c = (255,0,0)\n",
    "all_m_c = (0,255,0)\n",
    "bricks_c = (0,0,255)\n",
    "longtrans_c = (100,100,100)\n",
    "raveling_c = (100,100,0)\n",
    "blank_image = np.zeros([640,640,3],dtype=np.uint8)\n",
    "THRESHOLD = 0.05\n",
    "obb_model = YOLO('obb_model.pt')\n",
    "seg_model = YOLO('seg_model.pt')\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "class Distress:\n",
    "    mask = blank_image.copy()\n",
    "    color = (0,0,0)\n",
    "    area = 0\n",
    "    cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distress:\n",
    "    mask = blank_image.copy()\n",
    "    color = (0,0,0)\n",
    "    area = 0\n",
    "    cnt = 0\n",
    "\n",
    "def combine_distress(mask_img, new_mask, c):\n",
    "    return cv2.bitwise_or(mask_img, cv2.fillPoly(blank_image.copy(), pts=np.int32([new_mask]), color=c))\n",
    "\n",
    "def pred_seg_mdl(img_path):\n",
    "    results = seg_model(img_path, verbose=False, device=[0])\n",
    "    alligator_l = Distress()\n",
    "    alligator_m = Distress()\n",
    "    bricks = Distress()\n",
    "    longtrans = Distress()\n",
    "    raveling = Distress()\n",
    "\n",
    "    alligator_l.color = all_l_c\n",
    "    alligator_m.color = all_m_c\n",
    "    bricks.color = bricks_c\n",
    "    longtrans.color = longtrans_c\n",
    "    raveling.color = raveling_c\n",
    "    \n",
    "    for r in results:\n",
    "        id = 0\n",
    "        if r.masks is None:\n",
    "            continue\n",
    "        for mask in r.masks.xy:\n",
    "            cls = r.boxes.cls[id].item()\n",
    "            if r.boxes.conf[id] > THRESHOLD:\n",
    "                if cls == ALL_L:\n",
    "                    alligator_l.mask = combine_distress(alligator_l.mask, mask, alligator_l.color)\n",
    "                    alligator_l.cnt += 1\n",
    "                elif cls == ALL_M:\n",
    "                    alligator_m.mask = combine_distress(alligator_m.mask, mask, alligator_m.color)\n",
    "                    alligator_m.cnt += 1\n",
    "                elif cls == BRICKS:\n",
    "                    bricks.mask = combine_distress(bricks.mask, mask, bricks.color)\n",
    "                    bricks.cnt += 1\n",
    "                elif cls == LONGTRANS:\n",
    "                    longtrans.mask = combine_distress(longtrans.mask, mask, longtrans.color)\n",
    "                    longtrans.cnt += 1\n",
    "                elif cls == RAVELING:\n",
    "                    raveling.mask = combine_distress(raveling.mask, mask, raveling.color)\n",
    "                    raveling.cnt += 1\n",
    "            id += 1\n",
    "    return (alligator_l, alligator_m, bricks, longtrans, raveling)\n",
    "\n",
    "def create_keras_img_array(img):\n",
    "    new_img = cv2.resize(img, (img_width, img_height))\n",
    "    img_array = image.img_to_array(new_img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255\n",
    "    return img_array\n",
    "\n",
    "def get_mask(img_path):\n",
    "    distresses = pred_seg_mdl(img_path)\n",
    "    mask = blank_image.copy()\n",
    "    for d in distresses:\n",
    "        mask = cv2.bitwise_or(mask, d.mask)\n",
    "    return mask\n",
    "\n",
    "def apply_obb(img_path, alpha=0.3):\n",
    "    img = cv2.imread(img_path)\n",
    "    results = obb_model(img, verbose=False, device=[0])\n",
    "    \n",
    "    found = False\n",
    "    for r in results:\n",
    "        id = 0\n",
    "        if r.obb is None:\n",
    "            continue\n",
    "        for mask in r.obb.xyxyxyxyn:\n",
    "            if r.obb.conf[id] > THRESHOLD:\n",
    "                found = True\n",
    "                color = (255,0,0)\n",
    "                # mask is normlized to 0-1, so we need to multiply by the image size\n",
    "                # mask is tensor, so we need to convert it to numpy array\n",
    "                mask = mask.cpu().numpy()\n",
    "                mask = mask.reshape((-1,2))\n",
    "                mask[:,0] *= img.shape[1]\n",
    "                mask[:,1] *= img.shape[0]\n",
    "                # fill polygon with alpha\n",
    "                poly = cv2.fillPoly(img.copy(), pts=np.int32([mask]), color=color)\n",
    "                img = cv2.addWeighted(poly, alpha, img, 1-alpha, 0)\n",
    "            id += 1\n",
    "    return img\n",
    "\n",
    "def extract_seg_features(img_path:str):\n",
    "    original_img = create_keras_img_array(cv2.imread(img_path))\n",
    "    mask = create_keras_img_array(get_mask(img_path))\n",
    "\n",
    "    conv_original_img = conv_base.predict(original_img, verbose=0)\n",
    "    conv_mask = conv_base.predict(mask, verbose=0)\n",
    "\n",
    "    return np.array([np.concatenate((conv_original_img, conv_mask), axis=0)])\n",
    "\n",
    "def extract_obb_features(img_path, obb_model):\n",
    "    original_img = create_keras_img_array(cv2.imread(img_path))\n",
    "    obb_img = create_keras_img_array(apply_obb(img_path, obb_model))\n",
    "    \n",
    "    conv_original_img = conv_base.predict(original_img, verbose=0, use_multiprocessing=True)\n",
    "    conv_obb_img = conv_base.predict(obb_img, verbose=0, use_multiprocessing=True)\n",
    "    \n",
    "    return np.array([np.concatenate((conv_original_img, conv_obb_img), axis=0)])\n",
    "\n",
    "def extract_pci(train_csv):\n",
    "    pcis = {}\n",
    "    with open(train_csv, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = lines[1:]\n",
    "        for line in lines:\n",
    "            name = (line.split(',')[0] + ',' + line.split(',')[1]).replace('\"', '')\n",
    "            pci = int(line.split(',')[2])\n",
    "            pcis[name] = pci\n",
    "    return pcis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcis = extract_pci('train_v2/train.csv')\n",
    "def train_vector(img_dir:str):\n",
    "    features = np.array([])\n",
    "    labels = np.array([])\n",
    "    n = len(os.listdir(img_dir))\n",
    "    for img in tqdm(os.listdir(img_dir)):\n",
    "        img_path = os.path.join(img_dir, img)\n",
    "        img_features = extract_seg_features(img_path)\n",
    "        if features.size == 0:\n",
    "            features = img_features\n",
    "        else:\n",
    "            features = np.append(features, img_features, axis=0)\n",
    "        labels = np.append(labels, pcis[img])\n",
    "    return features, labels\n",
    "\n",
    "def train_obb_tensor(data_dir):\n",
    "    x_data = np.array([])\n",
    "    y_data = np.array([])\n",
    "    \n",
    "    for img in tqdm(os.listdir(data_dir)):\n",
    "        img_path = os.path.join(data_dir, img)\n",
    "        features = extract_obb_features(img_path, obb_model)\n",
    "        if x_data.size == 0:\n",
    "            x_data = features\n",
    "        else:\n",
    "            x_data = np.append(x_data, features, axis=0)\n",
    "        y_data = np.append(y_data, pcis[img])\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_x_train, seg_y_train = train_vector('train_v2/train')\n",
    "obb_x_train, obb_y_train = train_obb_tensor('train_v2/train')\n",
    "\n",
    "np.save('seg_x_train.npy', seg_x_train)\n",
    "np.save('seg_y_train.npy', seg_y_train)\n",
    "np.save('obb_x_train.npy', obb_x_train)\n",
    "np.save('obb_y_train.npy', obb_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_features = np.load('seg_x_train.npy')\n",
    "saved_labels = np.load('seg_y_train.npy')\n",
    "\n",
    "saved_labels[saved_labels < 0] = 0\n",
    "\n",
    "cop = saved_labels.copy()\n",
    "new_saved_labels = np.eye(101)[saved_labels.astype(int)]\n",
    "\n",
    "val_size = int(len(saved_features)*0.2)\n",
    "\n",
    "x_val = saved_features[:val_size]\n",
    "y_val = new_saved_labels[:val_size]\n",
    "x_train = saved_features[val_size:]\n",
    "y_train = new_saved_labels[val_size:]\n",
    "\n",
    "seg_model = Sequential() \n",
    "seg_model.add(Flatten(input_shape=(2,7,7,512)))\n",
    "seg_model.add(Dense(256, activation='relu'))\n",
    "seg_model.add(Dense(256, activation='relu'))\n",
    "seg_model.add(Dense(256, activation='relu'))\n",
    "seg_model.add(Dense(256, activation='relu'))\n",
    "seg_model.add(Dense(256, activation='relu'))\n",
    "seg_model.add(Dropout(0.5))\n",
    "seg_model.add(Dense(101, activation='sigmoid'))\n",
    "\n",
    "seg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='BinaryCrossentropy', metrics=['mean_squared_error', 'accuracy'])\n",
    "history = seg_model.fit(x_train, y_train, epochs=16, batch_size=16, validation_data=(x_val, y_val))\n",
    "seg_model.save('seg_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_features = np.load('obb_x_train.npy')\n",
    "saved_labels = np.load('obb_y_train.npy')\n",
    "\n",
    "saved_labels[saved_labels < 0] = 0\n",
    "\n",
    "cop = saved_labels.copy()\n",
    "new_saved_labels = np.eye(101)[saved_labels.astype(int)]\n",
    "\n",
    "val_size = int(len(saved_features)*0.2)\n",
    "\n",
    "x_val = saved_features[:val_size]\n",
    "y_val = new_saved_labels[:val_size]\n",
    "x_train = saved_features[val_size:]\n",
    "y_train = new_saved_labels[val_size:]\n",
    "\n",
    "seg_model = Sequential() \n",
    "seg_model.add(Flatten(input_shape=(2,7,7,512)))\n",
    "seg_model.add(Dense(256, activation='relu'))\n",
    "seg_model.add(Dense(256, activation='relu'))\n",
    "seg_model.add(Dense(256, activation='relu'))\n",
    "seg_model.add(Dense(256, activation='relu'))\n",
    "seg_model.add(Dense(256, activation='relu'))\n",
    "seg_model.add(Dropout(0.5))\n",
    "seg_model.add(Dense(101, activation='sigmoid'))\n",
    "\n",
    "seg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.000714), loss='BinaryCrossentropy', metrics=['mean_squared_error', 'accuracy'])\n",
    "history = seg_model.fit(x_train, y_train, epochs=20, batch_size=16, validation_data=(x_val, y_val))\n",
    "seg_model.save('obb_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_model = YOLO('yolov8s-cls.pt')\n",
    "class_model.train(data='class/data.yaml', epochs=35, imgsz=640, optimizer='AdamW', lr0=0.000714)\n",
    "\n",
    "model = YOLO('runs/classify/trainX/weights/best.pt')\n",
    "\n",
    "test_path = Path('test_v2/test/')\n",
    "rows = []\n",
    "for tst_img in test_path.glob('**/*.jpg'):\n",
    "    preds = model(tst_img)\n",
    "    cls_dict = preds[0].names\n",
    "    probs = preds[0].probs.data.cpu().numpy()\n",
    "    pred_pci=int(cls_dict[np.argmax(probs)])\n",
    "    rows.append({'image_name':os.path.basename(tst_img),\n",
    "                 'pci':max(0,min(100,pred_pci))})\n",
    "df_test = pd.DataFrame(rows)\n",
    "\n",
    "df_test.to_csv(\"class.csv\",header=True)\n",
    "def gen_submit(df):\n",
    "  out_json = []\n",
    "  for idx, results in df.iterrows():\n",
    "    out_json.append({results['image_name']:results['pci']})\n",
    "  with open('class.json', 'w') as f:\n",
    "    json.dump(out_json, f)\n",
    "\n",
    "df_test['pci'] = df_test['pci'].astype(int)\n",
    "gen_submit(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_pred(dir='', name=''):\n",
    "    path = os.path.join(dir, name)\n",
    "\n",
    "    features = extract_seg_features(path)\n",
    "    predictions = seg_model.predict(np.array([features]))\n",
    "    return (predictions[0])\n",
    "\n",
    "def obb_pred(dir='', name=''):\n",
    "    path = os.path.join(dir, name)\n",
    "\n",
    "    features = extract_obb_features(path, obb_model)\n",
    "    predictions = obb_model.predict(np.array([features]))\n",
    "    return (predictions[0])\n",
    "\n",
    "def gen_submit(df, name='submission.json'):\n",
    "    out_json = []\n",
    "    for idx, results in df.iterrows():\n",
    "        out_json.append({results['image_name']:results['PCI']})\n",
    "    with open(name, 'w') as f:\n",
    "        json.dump(out_json, f)\n",
    "\n",
    "def predict_seg_submission(test_dir):\n",
    "    names = []\n",
    "    preds = []\n",
    "    for img in tqdm(os.listdir(test_dir)):\n",
    "        pred = seg_pred(test_dir, img)\n",
    "        \n",
    "        preds.append(np.argmax(pred))\n",
    "        names.append(img)\n",
    "    df = pd.DataFrame({'image_name':names, 'PCI':preds})\n",
    "    gen_submit(df, 'seg.json')\n",
    "\n",
    "def predict_obb_submission(test_dir):\n",
    "    names = []\n",
    "    preds = []\n",
    "    for img in tqdm(os.listdir(test_dir)):\n",
    "        pred = obb_pred(test_dir, img)\n",
    "        \n",
    "        preds.append(np.argmax(pred))\n",
    "        names.append(img)\n",
    "    df = pd.DataFrame({'image_name':names, 'PCI':preds})\n",
    "    gen_submit(df, 'obb.json')\n",
    "\n",
    "predict_seg_submission('test_v2/test')\n",
    "predict_obb_submission('test_v2/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_submissions(class_json_path, seg_json_path, obb_json_path):\n",
    "    with open(class_json_path, 'r') as f:\n",
    "        class_json = json.load(f)\n",
    "    with open(seg_json_path, 'r') as f:\n",
    "        seg_json = json.load(f)\n",
    "    with open(obb_json_path, 'r') as f:\n",
    "        obb_json = json.load(f)\n",
    "        \n",
    "    class_files = [list(d.keys())[0] for d in class_json]\n",
    "    seg_files = [list(d.keys())[0] for d in seg_json]\n",
    "    obb_files = [list(d.keys())[0] for d in obb_json]\n",
    "    \n",
    "    class_values = [list(d.values())[0] for d in class_json]\n",
    "    seg_values = [list(d.values())[0] for d in seg_json]\n",
    "    obb_values = [list(d.values())[0] for d in obb_json]\n",
    "    \n",
    "    new_values = []\n",
    "    new_files = []\n",
    "    for file in class_files:\n",
    "        # take the min of the two values\n",
    "        class_v = class_values[class_files.index(file)]\n",
    "        seg_v = seg_values[seg_files.index(file)]\n",
    "        obb_v = obb_values[obb_files.index(file)]\n",
    "        \n",
    "        to_add = min(class_v, obb_v)\n",
    "        new_values.append(to_add)\n",
    "        new_files.append(file)\n",
    "    \n",
    "    df = pd.DataFrame({'image_name':new_files, 'PCI':new_values})\n",
    "    gen_submit(df, 'submission127.json')\n",
    "\n",
    "grab_submissions('class.json', 'seg.json', 'obb.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
